{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing TensorFlow Graphs in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rerequisites: This article assumes you are familiar with the basics of Python, TensorFlow, and Jupyter notebooks. We won't use any of the advanced TensorFlow features, as our goal is just to visualize the computation graphs.\n",
    "TensorFlow operations form a computation graph. And while for small examples you might be able to look at the code and immediately see what is going on, larger computation graphs might not be so obvious. Visualizing the graph can help both in diagnosing issues with the computation itself, but also in understanding how certain operations in TensorFlow work and how are things put together.\n",
    "We'll take a look at a few different ways of visualizing TensorFlow graphs, and most importantly, show how to do it in a very simple and time-efficient way. It shouldn't take more than one or two lines of code to draw a graph we have already defined. Now onto the specifics, we'll take a look at the following visualization techniques:\n",
    "Exploring the textual graph definition\n",
    "Building a GraphViz DOTgraph from that directly in the Jupyter Notebook\n",
    "Visualizing the same graph in a locally running instance of TensorBoard\n",
    "Using a self contained snippet that uses a cloud deployed publically available TensorBoard instance to render the graph inline in a Jupyter Notebook.\n",
    "First, let us create a simple TensorFlow graph. Regular operations such as creating a placeholder with tf.placeholder will create a node in the so called default graph. We can access it via tf.get_default_graph(), but we can also change it temporarily. In our example below, we'll create a new instance of the tf.Graph object and create a simple operation adding two variables\n",
    "c=a+b\n",
    " \n",
    "Note that we're giving explicit names to both of the placeholder variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = tf.placeholder(tf.float32, name=\"a\")\n",
    "    b = tf.placeholder(tf.float32, name=\"b\")\n",
    "    c = a + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable g now contains a definition of the computation graph for the operation  c=a+b\n",
    " . We can use the g.as_graph_def() method to get a textual representation of the graph for our expression. While the main use of this is for serialization and later deserialization via tf.import_graph_def, we'll use it to create a GraphViz DOTgraph.\n",
    "\n",
    "Let us take a look at the GraphDef for our simple expression. First, we'll inspect the names of all of the nodes in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'add']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[node.name for node in g.as_graph_def().node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there are three nodes in the Graph. One for each of our variables, and one for the addition opeartion. The placeholder variable nodes have a name since we explicitely named them when calling tf.placeholder. If we omit the name keyword argument, TensorFlow will simply generate a name on its own, as it did with the add operation.\n",
    "\n",
    "Next, we can take a look at the edges in the graph. Each GraphDef node has an input field which specifies of the nodes where it has edges. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.as_graph_def().node[2].input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are two edges, one to each variable. We can feed this directly into GraphViz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a GraphViz DOTgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphViz is a fairly popular library for drawing graphs, trees and other graph-shaped data structures. We'll use the Python GraphViz package which provides a nice clean interface. We can install it directly inside a Jupyter notebook via !pip install graphviz.\n",
    "\n",
    "The graph definition itself will be rather simple, and we'll take inspiration from a similar piece of code in TensorFlow itself (in graph_to_dot.py) which generates a DOTgraph file format for a given GraphDef. Unfortunately it is only available as a command line script, and as such we can't call it directly from our code. This is why we'll be implementing it ourselves, but don't worry, it will only be a few lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- a -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">a</text>\n",
       "</g>\n",
       "<!-- add -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>add</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">add</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;add -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>a&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M35.7146,-72.5708C39.9597,-64.0807 45.1536,-53.6929 49.8663,-44.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"53.024,-45.7782 54.3657,-35.2687 46.763,-42.6477 53.024,-45.7782\"/>\n",
       "</g>\n",
       "<!-- b -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>b</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">b</text>\n",
       "</g>\n",
       "<!-- b&#45;&gt;add -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>b&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M90.2854,-72.5708C86.0403,-64.0807 80.8464,-53.6929 76.1337,-44.2674\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.237,-42.6477 71.6343,-35.2687 72.976,-45.7782 79.237,-42.6477\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1127bab38>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph()\n",
    "\n",
    "for n in g.as_graph_def().node:\n",
    "    # Each node has a name and a label. The name identifies the node\n",
    "    # while the label is what will be displayed in the graph.\n",
    "    # We're using the name as a label for simplicity.\n",
    "    dot.node(n.name, label=n.name)\n",
    "    \n",
    "    for i in n.input:\n",
    "        # Edges are determined by the names of the nodes\n",
    "        dot.edge(i, n.name)\n",
    "        \n",
    "# Jupyter can automatically display the DOT graph,\n",
    "# which allows us to just return it as a value.\n",
    "dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's wrap this in a function and try using it on a more complicated expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_to_dot(graph):\n",
    "    dot = Digraph()\n",
    "\n",
    "    for n in g.as_graph_def().node:\n",
    "        dot.node(n.name, label=n.name)\n",
    "\n",
    "        for i in n.input:\n",
    "            dot.edge(i, n.name)\n",
    "            \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build another graph calculating the area of a circle with the formula  π∗r2\n",
    " . As we can see TensorFlow does what we would actually expect and links the same placeholder to two multiplication operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 134.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 130,-184 130,4 -4,4\"/>\n",
       "<!-- pi -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>pi</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">pi</text>\n",
       "</g>\n",
       "<!-- mul -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>mul</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"44\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"44\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mul</text>\n",
       "</g>\n",
       "<!-- pi&#45;&gt;mul -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>pi&#45;&gt;mul</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M31.2022,-144.2022C33.0821,-136.2406 35.3425,-126.6671 37.4371,-117.7957\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"40.8955,-118.3792 39.7872,-107.8425 34.0828,-116.7706 40.8955,-118.3792\"/>\n",
       "</g>\n",
       "<!-- r -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>r</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"99\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">r</text>\n",
       "</g>\n",
       "<!-- r&#45;&gt;mul -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>r&#45;&gt;mul</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M86.5196,-145.6621C79.4876,-136.4564 70.5653,-124.7764 62.7117,-114.4953\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"65.2828,-112.0953 56.431,-106.2733 59.72,-116.3446 65.2828,-112.0953\"/>\n",
       "</g>\n",
       "<!-- mul_1 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>mul_1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"71\" cy=\"-18\" rx=\"27.8951\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mul_1</text>\n",
       "</g>\n",
       "<!-- r&#45;&gt;mul_1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>r&#45;&gt;mul_1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M95.5104,-144.0535C90.7317,-119.4774 82.1029,-75.1008 76.4634,-46.0974\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.878,-45.3208 74.5336,-36.1727 73.0067,-46.6569 79.878,-45.3208\"/>\n",
       "</g>\n",
       "<!-- mul&#45;&gt;mul_1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>mul&#45;&gt;mul_1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M50.6742,-72.2022C53.7476,-64.0064 57.4616,-54.1024 60.8695,-45.0145\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"64.1685,-46.1853 64.4026,-35.593 57.6142,-43.7274 64.1685,-46.1853\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1127f5b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    pi = tf.constant(3.14, name=\"pi\")\n",
    "    r = tf.placeholder(tf.float32, name=\"r\")\n",
    "    \n",
    "    y = pi * r * r\n",
    "    \n",
    "tf_to_dot(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a local TensorBoard instance to visualize the graph\n",
    "\n",
    "While GraphViz might be nice for visualizing small graphs, neural networks can grow to quite a large size. TensorBoard allows us to easily group parts of our equations into scopes, which will then be visually separated in the resulting graph. But before doing this, let's just try visualizing our previous graph with TensorBoard.\n",
    "\n",
    "All we need to do is save it using the tf.summary.FileWriter, which takes a directory and a graph, and serializes the graph in a format that TensorBoard can read. The directory can be anything you'd like, just make sure you point to the same directory using the tensorboard --logdir=DIR command (DIR being the directory you specified to the FileWriter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We write the graph out to the `logs` directory\n",
    "tf.summary.FileWriter(\"logs\", g).close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next, open up a console and navigate to the same directory from which you executed the FileWriter command, and run tensorboard --logdir=logs. This will launch an instance of TensorBoard which you can access at http://localhost:6006. Then navigate to the Graphs section and you should see a graph that looks like the following image. Note that you can also click on the nodes in the graph to inspect them further."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://i.imgur.com/XajS4Tv.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is all nice and interactive, but we can already see some things which make it harder to read. For example, when we type  π∗r2\n",
    "  we generally don't think of the  r2\n",
    "  as a multiplication operation (even though we implement it as such), we think of it as a square operation. This becomes more visible when the graph contains a lot more operations.\n",
    "Luckily, TensorFlow allows us to bundle operations together into a single unit called scope. But first, lets take a look at a more complicated example without using scopes. We'll create a very simple feed forward neural network with three layers (with respective weights  W1,W2,W3\n",
    "  and biases  b1,b2,b3\n",
    " )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    X = tf.placeholder(tf.float32, name=\"X\")\n",
    "    \n",
    "    W1 = tf.placeholder(tf.float32, name=\"W1\")\n",
    "    b1 = tf.placeholder(tf.float32, name=\"b1\")\n",
    "    \n",
    "    a1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    \n",
    "    W2 = tf.placeholder(tf.float32, name=\"W2\")\n",
    "    b2 = tf.placeholder(tf.float32, name=\"b2\")\n",
    "    \n",
    "    a2 = tf.nn.relu(tf.matmul(a1, W2) + b2)\n",
    "\n",
    "    W3 = tf.placeholder(tf.float32, name=\"W3\")\n",
    "    b3 = tf.placeholder(tf.float32, name=\"b3\")\n",
    "    \n",
    "    y_hat = tf.matmul(a2, W3) + b3\n",
    "    \n",
    "tf.summary.FileWriter(\"logs\", g).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
